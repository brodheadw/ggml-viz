# GGML Visualizer

> **A cross‚Äëplatform, real‚Äëtime dashboard that lets you *****see***** what ºs happening inside any GGML‚Äëbased runtime ‚Äî from **`llama.cpp`** on a Raspberry Pi to **`whisper.cpp`** on an M3 Max.**

---

## 1 ‚Ä¢ Why does this exist?

Low‚Äëlevel LLM runtimes like **GGML** squeeze every last drop of performance out of CPUs and GPUs, but they are effectively a black box once the code is running.  Developers currently debug with `printf()` and perf logs ‚Äî painful and time‚Äëconsuming. **GGML Visualizer** removes that friction:

- **Graph view** ‚Äì static compute graph visualization with operation details
- **Timeline view** ‚Äì flame‚Äëchart showing kernel launches, thread utilisation, cache misses, and memory transfers (planned)
- **Tensor inspector** ‚Äì peek at activations, histograms, min/max, sparsity, quantisation buckets (planned)
- **Attention heat‚Äëmap** ‚Äì for transformer models, display token‚Äëby‚Äëtoken attention scores (planned)
- **Memory arena explorer** ‚Äì visualise GGML ºs bump‚Äëallocator, fragmentation, and live/peak usage (planned)

---

## 2 ‚Ä¢ Features at a glance

| Category          | Feature                                            | Status    |
| ----------------- | -------------------------------------------------- | --------- |
| **Graph**         | Static compute graph visualization                 | ‚úÖ Ready   |
|                   | Static graph import (`ggml_graph_dump_dot`)        | ‚úÖ Ready   |
| **Timeline**      | CPU & GPU kernel flame‚Äëchart                       | ‚ùå Planned |
| **Tensors**       | On‚Äëhover statistics (mean/œÉ, sparsity)             | ‚ùå Planned |
|                   | Slice & heat‚Äëmap viewer                            | ‚ùå Planned |
| **Memory**        | Live arena visual + peak tracker                   | ‚ùå Planned |
| **Model‚Äëaware**   | Transformer attention & KV‚Äëcache heat‚Äëmaps         | ‚ùå Planned |
| **Extensibility** | Plugin SDK (C++)                                   | ‚ùå Planned |

Legend: ‚úÖ = production‚Äëready ¬∑ üõ† = usable but polishing ¬∑ ‚ùå = stub / not started

---

## 3 ‚Ä¢ Quick start (90 seconds)

### 3.1 Install prerequisites

```bash
# Ubuntu / Debian
sudo apt update && sudo apt install -y git cmake build-essential libgl1-mesa-dev libxinerama-dev libxcursor-dev libxi-dev libxrandr-dev

# macOS (Apple Silicon & Intel)
brew install cmake glfw
```

### 3.2 Build

```bash
git clone --recursive [REPOSITORY_URL_TBD]
cd ggml‚Äëvisualizer
mkdir build && cd build

# macOS (recommended due to Metal shader issues)
cmake .. -DCMAKE_BUILD_TYPE=Release -DGGML_METAL=OFF

# Linux/Ubuntu
cmake .. -DCMAKE_BUILD_TYPE=Release

make -j4
```

### 3.3 Capture and visualize llama.cpp

```bash
# Step 1: Set environment variable for trace capture
export GGML_VIZ_OUTPUT=my_llama_trace.ggmlviz

# Step 2: Run llama.cpp normally (hooks auto-capture GGML events)
/path/to/llama.cpp/main -m /path/to/model.gguf -p "Hello, world!" -n 50

# Step 3: Visualize the captured data
./bin/ggml-viz my_llama_trace.ggmlviz
```

The dashboard opens automatically showing the captured inference data. For more options:

```bash
# Show help with all available options
./bin/ggml-viz --help

# Load existing trace file
./bin/ggml-viz tests/traces/trace.ggmlviz

# Enable verbose output
./bin/ggml-viz --verbose tests/traces/trace.ggmlviz

# Live mode (experimental - not fully implemented)
./bin/ggml-viz --live --port 8080
```

---

## 4 ‚Ä¢ Architecture

```mermaid
graph TD
  subgraph GGML Runtime
    GG[ggml.c] -->|calls| Hook[Instrumentation hooks]
  end
  Hook --> IPC{{Zero‚ÄëCopy IPC}}
  IPC -->|shared structs| ServerCore([
    Data‚ÄëCollector
    ‚Ä¢ ring-buffer events    ‚Ä¢ tensor snapshots
  ])
  ServerCore --> API{{gRPC / WebSocket}}
  API --> UI[Planned Electron/ImGui front‚Äëend ]
```

- **Instrumentation hooks** ‚Äì small patch (\~200 LOC) to GGML that triggers a callback before/after each op; can be upstreamed.
- **Zero‚ÄëCopy IPC** ‚Äì POSIX shared memory on Unix, `CreateFileMapping` on Windows (planned).
- **Front‚Äëend** ‚Äì Desktop ImGui build (ready) or optional Electron client for web dashboards (planned).

---

## 5 ‚Ä¢ Supported platforms & back‚Äëends

| OS / Arch                  | CPU (AVX2 / AVX‚Äë512 / NEON) | GPU (Metal / CUDA / Vulkan) | Status |
| -------------------------- | --------------------------- | --------------------------- | ------ |
| macOS 12+ (arm64, x86\_64) | ‚úîÔ∏é                          | CPU only*                   | ‚úÖ      |
| Linux (x86\_64)            | ‚úîÔ∏é                          | CUDA 11+, Vulkan            | ‚úÖ      |
| Windows 10+                | ‚úîÔ∏é                          | Untested                     | ‚ùå     |
| Raspberry Pi 5             | ‚úîÔ∏é (NEON)                   | ‚Äî                           | üõ†     |

*Metal backend disabled by default due to shader compilation issues

Performance overhead: ~1-2% (preliminary - see [BENCHMARKING.md](docs/BENCHMARKING.md) for details and critical issues).

**Recent Fix**: Critical bug resolved - instrumentation now properly records events (was recording 0 events, now records 60+ events per test run).

---

## 6 ‚Ä¢ Roadmap (2025‚ÄëQ3)

- **0.2.0** ‚Äì Full CPU timeline, tensor heat‚Äëmaps, KV‚Äëcache view ‚ú®
- **0.3.0** ‚Äì GPU kernel correlation (Metal & CUDA), quant‚Äëbucket viewer
- **0.4.0** ‚Äì Plugin SDK v1 + Python bindings
- **0.5.0** ‚Äì Attention & router head visualizer, export to SVG/JSON

See [`docs/CHANGELOG.md`](docs/CHANGELOG.md) for granular history.

---

## 7 ‚Ä¢ Contributing

1. **Pick an issue** tagged `good‚Äëfirst‚Äëissue` or `help‚Äëwanted`.
2. Fork ‚Üí feature branch ‚Üí PR. Code formatting and linting TBD.
3. Each PR must pass tests (CI setup TBD).
4. Follow project guidelines (contributor agreement TBD).

We especially welcome:

- **UI/UX polishers** (ImGui, Dear ImGui Docking, Electron)
- **GPU devs** ‚Äì Metal shaders & CUDA kernel tracing
- **Model folk** ‚Äì attention/KV‚Äëcache interpretation modules

---

## 8 ‚Ä¢ Quick reference

### Build and test commands:
```bash
# Build (macOS)
mkdir -p build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release -DGGML_METAL=OFF
make -j4

# Test
./tests/manual/test_ggml_hook
./bin/test_trace_reader tests/assets/test_trace.ggmlviz

# Run visualizer
./bin/ggml-viz --help
```

### Environment variables:
- `GGML_VIZ_OUTPUT`: Output trace file (required for capture)
- `GGML_VIZ_VERBOSE`: Enable verbose logging
- `GGML_VIZ_DISABLE`: Disable instrumentation entirely

### Performance benchmarking:
```bash
# Quick performance check
./scripts/simple_benchmark.sh

# Comprehensive analysis
./scripts/benchmark.sh
```

---

## 9 ‚Ä¢ License

`ggml‚Äëvisualizer` is licensed under the **Apache 2.0** license. See `docs/THIRD_PARTY.md` for dependency licenses.

---

## 10 ‚Ä¢ Credits & Inspiration

- Georgi Gerganov and the **GGML** community for the blazing‚Äëfast runtime.
- Anthropic ºs **Neuronpedia** and Meta ºs **LLM Transparency Tool** for paving the way in model interpretability.
- **Tracy** profiler for showing that real‚Äëtime, low‚Äëoverhead visualisation is possible in C++.

*"The best debugger is a graphical one you can keep open while your model runs."* ‚Äì Me

---

## Implementation Status Summary

### ‚úÖ **Working Components**
- **Core instrumentation** - Complete GGML hook infrastructure with event capture
- **Auto-initialization** - Environment variable configuration system
- **Main executable** - Full CLI argument parsing with help, version, validation
- **ImGui frontend** - Desktop UI with trace file loading capability
- **Custom ImGui widgets** - Graph visualization, timeline, inspection widgets
- **Trace reader** - Binary .ggmlviz file parsing and event replay

### üõ† **Partially Implemented**  
- **Injection scripts** - macOS/Linux dynamic library injection helpers
- **Live mode** - CLI option exists but functionality not fully implemented
- **Configuration loading** - CLI option exists but not implemented

### ‚ùå **Empty Stubs Requiring Implementation**
- **IPC layer** - Cross-platform shared memory (POSIX/Windows)
- **Plugin system** - Dynamic loading API and plugin loader
- **gRPC server** - Remote API for live data access
- **Advanced visualizations** - Timeline, tensor stats, memory tracking
- **Development tools** - Linting, formatting, and test execution scripts

### üöÄ **Current Usability**
The instrumentation core is production-ready. You should be able to instrument any GGML application by setting `GGML_VIZ_OUTPUT`, generate .ggmlviz trace files, and visualize them in the desktop UI. If this isn't the case, please contact the maintainers (Will Brodhead). The CLI is fully functional with comprehensive help and validation.

### üì¶ **Project Structure & Submodules**

The project is organized with a modular architecture using git submodules for external dependencies:

#### **Git Submodules**
- **`third_party/ggml`** - Fork of GGML tensor library with backend hooks ([brodheadw/willb-ggml](https://github.com/brodheadw/willb-ggml))
- **`third_party/llama.cpp`** - Fork with Metal backend hooks ([brodheadw/llama.cpp](https://github.com/brodheadw/llama.cpp))
- **`third_party/glfw`** - OpenGL window management (upstream)
- **`third_party/imgui`** - Immediate mode GUI framework (upstream)

#### **Metal Backend Integration**
The llama.cpp submodule uses a custom fork with visualization hooks:
- **Branch**: `ggml-viz-hooks` 
- **Modifications**: Universal backend interception at `ggml_backend_graph_compute()`
- **Coverage**: All backends (Metal, CPU, CUDA, Vulkan) through single integration point
- **Compatibility**: Weak symbols allow dynamic library injection without code changes